{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For packs detection we use COCO dataset pretrained model SSD (single shot detection) mobilenet V1.<br>\n",
    "Training a model from the the beginning could take days even with powerfull system. So, we use <br>\n",
    "knowledge transfer technique training already working model on new types of objects.<br>\n",
    "Event though Tensorflow Object Detection can augment data, randomly crop parts of image with my<br>\n",
    "slow hard drive, 16GB memory, and far from top GPU it is not possible to use images as they were provided<br>\n",
    "So, what I'm going to do is to randomly crop images myself, shrink them to 300x300 and merge everything to<br>\n",
    "tensorflow train and eval files.<br>\n",
    "In data/images folder create detection folder with eval and train subfloders inside. We will put crops there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrey/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current images path \n",
    "img_path = 'data/images/ShelfImages/'\n",
    "# cropped parts destination\n",
    "cropped_path = 'data/images/detector/'\n",
    "# Step 1 results path\n",
    "data_path = 'data/'\n",
    "# output destination\n",
    "detector_data_path = 'pack_detector/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read rects and photos dataframes\n",
    "photos = pd.read_pickle(f'{data_path}photos.pkl')\n",
    "products = pd.read_pickle(f'{data_path}products.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TEST_CROP is True, every product on cropped image part will have\n",
    "# bounding box for checking purpose. For training it should be False\n",
    "TEST_CROP = False\n",
    "# how many times we will try to crop each image\n",
    "N_CROP_TRIALS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns random value in [s, f]\n",
    "def rand_between(s, f):\n",
    "    if s == f:\n",
    "        return s\n",
    "    return np.random.randint(s, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_products, eval_products = [], []\n",
    "for img_file, is_train in photos[['file', 'is_train']].values:\n",
    "    img = cv2.imread(f'{img_path}{img_file}')\n",
    "    img_h, img_w, img_c = img.shape\n",
    "    for n in range(N_CROP_TRIALS):\n",
    "        # random crop rectangle\n",
    "        x0 = rand_between(0, img_w - 1)\n",
    "        x1 = rand_between(x0, img_w - 1)\n",
    "        y0 = rand_between(0, img_h - 1)\n",
    "        y1 = rand_between(y0, img_h - 1)\n",
    "        # products totally inside crop rectangle\n",
    "        crop_products = products[(products.file == img_file) & (products.xmin > x0) & \n",
    "                                 (products.ymin > y0) & (products.xmax < x1) & \n",
    "                                 (products.ymax < y1)]\n",
    "        # no products inside crop rectangle? cropping trial failed...\n",
    "        if len(crop_products) == 0:\n",
    "            continue\n",
    "        # name the crop\n",
    "        crop_img_file = f'{img_file[:-4]}{x0}_{y0}_{x1}_{y1}.JPG'\n",
    "        # crop and reshape to 300x300 or smaller keeping aspect ratio\n",
    "        crop = img[y0:y1, x0:x1]\n",
    "        h, w, c = crop.shape\n",
    "        ratio = min(300/h, 300/w)\n",
    "        crop = cv2.resize(crop, (0,0), fx=ratio, fy=ratio)[0:300, 0:300]\n",
    "        h, w, c = crop.shape\n",
    "        # add crop inner products to train_products or eval_products list\n",
    "        for xmin, ymin, xmax, ymax in crop_products[['xmin', 'ymin', 'xmax', 'ymax']].values:\n",
    "            xmin -= x0\n",
    "            xmax -= x0\n",
    "            ymin -= y0\n",
    "            ymax -= y0\n",
    "\n",
    "            xmin, xmax, ymin, ymax = [int(np.round(e * ratio)) for e in [xmin, xmax, ymin, ymax]]\n",
    "            product = {'filename': crop_img_file, 'class':'pack', \n",
    "                       'width':w, 'height':h,\n",
    "                       'xmin':xmin, 'ymin':ymin, 'xmax':xmax, 'ymax':ymax}\n",
    "            if is_train:\n",
    "                train_products.append(product)\n",
    "            else:\n",
    "                eval_products.append(product)\n",
    "            if TEST_CROP:\n",
    "                crop = cv2.rectangle(crop, (xmin, ymin), (xmax, ymax), (255,0,0), 5)\n",
    "        # save crop top eval or train folder\n",
    "        subpath = ['eval/', 'train/'][is_train]\n",
    "        cv2.imwrite(f'{cropped_path}{subpath}{crop_img_file}', crop)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_products).set_index('filename')\n",
    "eval_df = pd.DataFrame(eval_products).set_index('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'pack':\n",
    "        return 1\n",
    "    else:\n",
    "        None\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tf_records(images_path, examples, dst_file):\n",
    "    writer = tf.python_io.TFRecordWriter(dst_file)\n",
    "    grouped = split(examples, 'filename')\n",
    "    for group in grouped:\n",
    "        tf_example = create_tf_example(group, images_path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_tf_records(f'{cropped_path}train/', train_df, f'{detector_data_path}train.record')\n",
    "convert_to_tf_records(f'{cropped_path}eval/', eval_df, f'{detector_data_path}eval.record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python3 train.py --logtostderr --train_dir=pack_training/ --pipeline_config_path=pack_training/ssd_mobilenet_v2_coco.config\n",
    "#~/work/models/research/object_detection/pack_detector/models/ssd_mobilenet_v1\n",
    "#python3 train.py --logtostderr --train_dir=pack_detector/models/ssd_mobilenet_v1/train/ --pipeline_config_path=pack_detector/models/ssd_mobilenet_v1/ssd_mobilenet_v1_pack.config\n",
    "#CUDA_VISIBLE_DEVICES=\"\" python3 eval.py --logtostderr --checkpoint_dir=pack_detector/models/ssd_mobilenet_v1/train --pipeline_config_path=pack_detector/models/ssd_mobilenet_v1/ssd_mobilenet_v1_pack.config --eval_dir=pack_detector/models/ssd_mobilenet_v1/eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (with Tensorflow GPU)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
